{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoodHunt v3+ RL Trading Bot — Colab Demo\n",
    "\n",
    "Profit-optimized RL framework for multi-asset trading. \n",
    "\n",
    "Covers: Data, Feature Engineering, Training, Backtest, Plots, Configs.\n",
    "\n",
    "*(Requires Python 3.9+ and Stable Baselines3)*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ⬇️ Install dependencies\n",
    "!pip install yfinance pandas numpy matplotlib stable-baselines3 gymnasium pyyaml"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ⬇️ Clone and Setup (if using GitHub repo)\n",
    "# !git clone https://github.com/YOURUSER/goodhunt-v3.git\n",
    "# %cd goodhunt-v3\n",
    "\n",
    "# Or upload code files below if running standalone."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ⚙️ Config YAML (edit here or upload your own)\n",
    "import yaml\n",
    "config = {\n",
    "    'data': {'assets': ['AAPL'], 'interval': '1d', 'start': '2023-01-01', 'end': '2024-06-30'},\n",
    "    'env': {'initial_balance': 100.0, 'window_size': 50, 'fee_pct': 0.001, 'slippage_pct': 0.0015,\n",
    "            'liquidity_threshold': 1000, 'position_sizing': 'volatility', 'exposure_cap': 0.7,\n",
    "            'profit_target': 0.05, 'stop_loss': 0.03, 'max_drawdown': 0.05},\n",
    "    'reward': {'mode': 'sharpe', 'decay': 0.995, 'win_boost': 0.01, 'hold_penalty': 0.01,\n",
    "               'chaos_flat_bonus': 0.02, 'reward_clip': 2.0},\n",
    "    'agent': {'algo': 'PPO', 'total_timesteps': 10000, 'policy': 'MlpPolicy',\n",
    "              'tensorboard_log': 'tensorboard', 'multi_agent': False},\n",
    "    'logging': {'log_dir': 'logs', 'trade_log': 'backtest/trades.csv',\n",
    "                'equity_curve': 'backtest/equity_curve.csv', 'plot_dir': 'backtest/plots', 'tensorboard': True},\n",
    "    'backtest': {'test_split': 0.2, 'multi_asset': False, 'plot_equity_curve': True, 'plot_confusion_matrix': True}\n",
    "}\n",
    "with open('utils/config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "print('Config written to utils/config.yaml')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from data.fetch_data import get_data\n",
    "from utils.indicators import add_all_indicators\n",
    "from utils.patterns import add_patterns\n",
    "from utils.regime import detect_regime\n",
    "\n",
    "df = get_data(symbol='AAPL', start='2023-01-01', end='2024-06-30', interval='1d', preprocess=False, save=False)\n",
    "df = add_all_indicators(df)\n",
    "df = add_patterns(df)\n",
    "df = detect_regime(df)\n",
    "\n",
    "df.tail()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train RL Agent"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from env.trading_env import TradingEnv\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "env = DummyVecEnv([lambda: TradingEnv(df)])\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=\"tensorboard\")\n",
    "model.learn(total_timesteps=10000)\n",
    "model.save('models/demo_ppo_model')\n",
    "print('Model trained and saved.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Backtest & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from env.trading_env import TradingEnv\n",
    "model = PPO.load('models/demo_ppo_model')\n",
    "env = TradingEnv(df)\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "env.save_trades('backtest/trades.csv')\n",
    "env.save_equity_curve('backtest/equity_curve.csv')\n",
    "print('Backtest done. Logs saved.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eq = pd.read_csv('backtest/equity_curve.csv')\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(eq['net_worth'])\n",
    "plt.title('Equity Curve')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Net Worth')\n",
    "plt.show()\n",
    "\n",
    "trades = pd.read_csv('backtest/trades.csv')\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.scatter(trades['step'], trades['pnl'], c=(trades['pnl']>0), cmap='bwr', label='Trade PnL')\n",
    "plt.title('Trade PnL by Step')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('PnL')\n",
    "plt.axhline(0, color='gray', linestyle='--')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Config & Advanced Experiments\n",
    "\n",
    "- Edit `utils/config.yaml` and re-run cells to tune reward, agent, or env.\n",
    "- Try multi-asset: set `assets: ['AAPL', 'TSLA']` in config and retrain.\n",
    "- Use `main.py` for advanced CLI (train/test/grid)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
